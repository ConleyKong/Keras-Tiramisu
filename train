#!/usr/bin/python

import argparse
import os
import pickle

from keras import optimizers
from keras.callbacks import ModelCheckpoint
from keras.callbacks import TensorBoard
from keras.utils import plot_model


import model
from utils import data_generator, Visualization


parser = argparse.ArgumentParser()
parser.add_argument('--batch_size', type=int, default=4, help='input batch size')
parser.add_argument('--image_width', type=int, default=640, help='the input image width')
parser.add_argument('--image_height', type=int, default=360, help='the input image height')
parser.add_argument('--crop_width', type=int, default=224, help='the crop width')
parser.add_argument('--crop_height', type=int, default=224, help='the crop height')
parser.add_argument('--random_flip', type=bool, default=True, help='Do random horizontal flip during training')
parser.add_argument('--epochs', type=int, default=1000, help='number of epochs to train for')
parser.add_argument('--lr', type=float, default=1e-3, help='learning rate of the optimizer')
parser.add_argument('--decay', type=float, default=1e-4, help='learning rate decay (per batch update)')
parser.add_argument('--gpu', type=int, default=0, help='GPU to use')
parser.add_argument('--weights', type=str, default='weights.h5', help='output path for the weights file')
opt = parser.parse_args()

print(opt)

# Set the GPU to use
os.environ["CUDA_VISIBLE_DEVICES"] = str(opt.gpu)

# Callbacks
checkpoint = ModelCheckpoint(opt.weights, save_best_only=True, save_weights_only=True, verbose=1)
tensorboard = TensorBoard(batch_size=opt.batch_size)
visualization = Visualization(resize_shape=(opt.crop_width, opt.crop_height), batch_steps=10, name=str(opt.gpu))

# Load class weights
#class_weights = pickle.load(open("class_weights.p", "rb"))
class_weights = []

#### Train initially with random crops ####

# Generators
train_generator = data_generator(batch_size=opt.batch_size, crop_shape=(opt.crop_width, opt.crop_height), resize_shape=(opt.image_width, opt.image_height), horizontal_flip=opt.random_flip)
val_generator = data_generator(mode='validation', batch_size=opt.batch_size, crop_shape=(opt.crop_width, opt.crop_height), resize_shape=(opt.image_width, opt.image_height), horizontal_flip=opt.random_flip)

optim = optimizers.Adam(lr=opt.lr, decay=opt.decay)
tiramisu = model.build(opt.crop_width, opt.crop_height, 66)
tiramisu.compile(optim, 'categorical_crossentropy', metrics=['categorical_accuracy'])
tiramisu.fit_generator(train_generator, 18000/opt.batch_size, opt.epochs, callbacks=[checkpoint, tensorboard, visualization], 
                       validation_data=val_generator, validation_steps=2000/opt.batch_size, class_weight=class_weights)
                       
#### Finetune with full size image and lower learning rate ####
                       
# Generators
train_generator = data_generator(batch_size=opt.batch_size, crop_shape=None, resize_shape=(opt.image_width, opt.image_height), horizontal_flip=opt.random_flip)
val_generator = data_generator(mode='validation', batch_size=opt.batch_size, crop_shape=None, resize_shape=(opt.image_width, opt.image_height), horizontal_flip=opt.random_flip)                       

optim = optimizers.Adam(lr=opt.lr/10)
tiramisu = model.build(opt.image_width, opt.image_height, 66, weights_path=opt.weights)
tiramisu.compile(optim, 'categorical_crossentropy', metrics=['categorical_accuracy'])
tiramisu.fit_generator(train_generator, 18000/opt.batch_size, opt.epochs, callbacks=[checkpoint, tensorboard, visualization], 
                       validation_data=val_generator, validation_steps=2000/opt.batch_size, class_weight=class_weights)
